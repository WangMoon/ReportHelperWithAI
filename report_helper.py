import streamlit as st
from openai import OpenAI
import os
import subprocess


# è®¾ç½® Streamlit é¡µé¢
st.set_page_config(page_title="Web for SIDRI PYAUTOCAD", page_icon="ğŸ¦œğŸ”—")
st.title("ç§‘æ ‡ä¸šé¡¹ç›®ä»»åŠ¡ä¹¦è‡ªåŠ¨åŒ–ç”Ÿæˆä¸æ¶¦è‰²åŠ©æ‰‹")

# è®¾ç½® OpenAI API å¯†é’¥
client = OpenAI(
    # This is the default and can be omitted
    api_key = "sk-E1CARH7sAvjVIOUgx1UkYn3pvzFX5c75oHhuULeNE6pCO3n1" ,
    base_url = "https://api.moonshot.cn/v1" ,
)

# å•è½®å¯¹è¯
# completion = client.chat.completions.create(
#     model = "moonshot-v1-8k",
#     messages = [
#         {"role": "system", "content": "ä½ æ˜¯ Kimiï¼Œç”± Moonshot AI æä¾›çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œä½ æ›´æ“…é•¿ä¸­æ–‡å’Œè‹±æ–‡çš„å¯¹è¯ã€‚ä½ ä¼šä¸ºç”¨æˆ·æä¾›å®‰å…¨ï¼Œæœ‰å¸®åŠ©ï¼Œå‡†ç¡®çš„å›ç­”ã€‚åŒæ—¶ï¼Œä½ ä¼šæ‹’ç»ä¸€åˆ‡æ¶‰åŠææ€–ä¸»ä¹‰ï¼Œç§æ—æ­§è§†ï¼Œé»„è‰²æš´åŠ›ç­‰é—®é¢˜çš„å›ç­”ã€‚Moonshot AI ä¸ºä¸“æœ‰åè¯ï¼Œä¸å¯ç¿»è¯‘æˆå…¶ä»–è¯­è¨€ã€‚"},
#         {"role": "user", "content": "ä½ å¥½ï¼Œæˆ‘å«æé›·ï¼Œ1+1ç­‰äºå¤šå°‘ï¼Ÿ"}
#     ],
#     temperature = 0.3,
# )
 
# print(completion.choices[0].message.content)



# å¤šè½®å¯¹è¯
history = [
    {"role": "system", "content": "ä½ æ˜¯ Kimiï¼Œç”± Moonshot AI æä¾›çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œä½ æ›´æ“…é•¿ä¸­æ–‡å’Œè‹±æ–‡çš„å¯¹è¯ã€‚ä½ ä¼šä¸ºç”¨æˆ·æä¾›å®‰å…¨ï¼Œæœ‰å¸®åŠ©ï¼Œå‡†ç¡®çš„å›ç­”ã€‚åŒæ—¶ï¼Œä½ ä¼šæ‹’ç»ä¸€åˆ‡æ¶‰åŠææ€–ä¸»ä¹‰ï¼Œç§æ—æ­§è§†ï¼Œé»„è‰²æš´åŠ›ç­‰é—®é¢˜çš„å›ç­”ã€‚Moonshot AI ä¸ºä¸“æœ‰åè¯ï¼Œä¸å¯ç¿»è¯‘æˆå…¶ä»–è¯­è¨€ã€‚"}
]
 
def chat(query, history):
    history.append({
        "role": "user", 
        "content": query
    })
    completion = client.chat.completions.create(
        model="moonshot-v1-auto",
        messages=history,
        temperature=0.3,
    )
    result = completion.choices[0].message.content
    history.append({
        "role": "assistant",
        "content": result
    })
    return result
 
print(chat("åœ°çƒçš„è‡ªè½¬å‘¨æœŸæ˜¯å¤šå°‘ï¼Ÿ", history))
print(chat("æœˆçƒå‘¢ï¼Ÿ", history))

# åˆå§‹åŒ– OpenAI æ¨¡å‹
@st.cache_resource
def init_models():
    return None

# æ£€æŸ¥æ˜¯å¦éœ€è¦åˆå§‹åŒ–æ¨¡å‹
if 'query_engine' not in st.session_state:
    st.session_state['query_engine'] = init_models()

# å‡½æ•°ï¼šä½¿ç”¨ OpenAI çš„ API ç”Ÿæˆå“åº”
def greet2(question):
    try:
        chat_completion = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": question}
            ],
            max_tokens=4000,
            temperature=0.7,          
        )
        return chat_completion.choices[0].message.content
    except Exception as e:
        return f"Error: {str(e)}"

# ä¿å­˜ LLM ç”Ÿæˆçš„å“åº”
if "messages" not in st.session_state.keys():
    st.session_state.messages = [{"role": "assistant", "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„ç¼–ç¨‹åŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"}]

# æ˜¾ç¤ºæˆ–æ¸…é™¤èŠå¤©æ¶ˆæ¯
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# å‡½æ•°ï¼šæ¸…é™¤èŠå¤©è®°å½•
def clear_chat_history():
    st.session_state.messages = [{"role": "assistant", "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„åŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"}]

    # åˆ é™¤ chat_log.py æ–‡ä»¶
    try:
        os.remove('chat_log.py')  # ç¡®ä¿è·¯å¾„æ­£ç¡®
    except FileNotFoundError:
        st.warning("å·²åˆ é™¤")

st.sidebar.button('æ¸…é™¤èŠå¤©å†å²', on_click=clear_chat_history)

# å‡½æ•°ï¼šç”Ÿæˆ ChatGPT å“åº”
def generate_llama_index_response(prompt_input):
    return greet2(prompt_input)

# ç”¨æˆ·è¾“å…¥çš„æç¤º
if prompt := st.chat_input():
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)

# ç”Ÿæˆ OpenAI API å“åº”
if st.session_state.messages[-1]["role"] != "assistant":
    with st.chat_message("assistant"):
        with st.spinner("Thinking..."):
            response = generate_llama_index_response(prompt)
            placeholder = st.empty()
            placeholder.markdown(response)
    message = {"role": "assistant", "content": response}
    st.session_state.messages.append(message)

# å‡½æ•°ï¼šä¿å­˜èŠå¤©è®°å½•åˆ°æ–‡ä»¶          
def save_to_file():
    file_content = ""
    
    for msg in st.session_state.messages:
        content = msg['content']
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ä»£ç å—ï¼ˆå‡è®¾ä»£ç å—ä½¿ç”¨ä¸‰ä¸ªåå¼•å· ``` åŒ…è£¹ï¼‰
        code_blocks = content.split("```")
        if len(code_blocks) >= 3:
            # è¿‡æ»¤æ‰è§£é‡Šæ€§æ–‡å­—ï¼Œåªæå–åå¼•å·åŒ…è£¹çš„ä»£ç éƒ¨åˆ†
            for i in range(1, len(code_blocks), 2):  # è·³è¿‡éä»£ç éƒ¨åˆ†
                code_content = code_blocks[i].strip()

                # å¦‚æœä»£ç å—ä»¥æŸäº›ç¼–ç¨‹è¯­è¨€å‰ç¼€ï¼ˆå¦‚ pythonï¼‰å¼€å¤´ï¼Œåˆ é™¤è¯¥å‰ç¼€,å¹¶æŠ“å–è¯¥ä»£ç 
                if code_content.startswith("python"):
                    code_content = code_content[len("python"):].strip()  # åˆ é™¤ "python" å‰ç¼€å¹¶å»æ‰å¤šä½™çš„ç©ºæ ¼
                    file_content += f"{code_content}\n"  # å°†ä»£ç å†…å®¹æ·»åŠ åˆ°æ–‡ä»¶ä¸­

    file_path = "chat_log.py"
    
    if file_content:  # å¦‚æœ file_content ä¸ä¸ºç©º
        # ä½¿ç”¨ UTF-8 ç¼–ç å†™å…¥æ–‡ä»¶
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(file_content)
        st.success(f"æ–‡ä»¶å·²ç”Ÿæˆ: {file_path}")
    else:
        st.warning("æ²¡æœ‰æå–åˆ°ä»»ä½•ä»£ç å—")
    
    return file_path

# å‡½æ•°ï¼šè¿è¡Œç”Ÿæˆçš„æ–‡ä»¶
def run_file(file_path):
    try:
        result = subprocess.run(['python', file_path], capture_output=True, text=True)
        st.text(f"è¿è¡Œç»“æœ: \n{result.stdout}")
    except Exception as e:
        st.error(f"è¿è¡Œæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")

# æ·»åŠ æŒ‰é’®ï¼Œç”Ÿæˆå¹¶è¿è¡Œæ–‡ä»¶
if st.sidebar.button('ç”Ÿæˆæ¨¡å‹'):
    file_path = save_to_file()
    run_file(file_path)